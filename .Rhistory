colnames(station_data) <- c('station','year','month',1:31)
head(station_data,5)
vertical_data <- gather(station_data, key = day, value = precip, 4:34)
vertical_data$date <- as.Date(paste(as.character(vertical_data$year),
as.character(vertical_data$month),
as.character(vertical_data$day),sep = '-'))
head(vertical_data,5)
consol_data <- data.frame(date = seq.Date(as.Date('1911-1-1'),as.Date('2020-12-31'),by = 'day'))
head(consol_data,5)
consol_data$precip <- vlookup(consol_data$date, vertical_data, result_column = 5,
lookup_column = 6)
head(consol_data,5)
class(consol_data)
class(consol_data)
station_data <- read.delim('739038.txt')
colnames(station_data) <- c('station','year','month',1:31)
head(station_data,5)
vertical_data <- gather(station_data, key = day, value = precip, 4:34)
vertical_data$date <- as.Date(paste(as.character(vertical_data$year),
as.character(vertical_data$month),
as.character(vertical_data$day),sep = '-'))
head(vertical_data,5)
consol_data <- data.frame(date = seq.Date(as.Date('1911-1-1'),as.Date('2020-12-31'),by = 'day'))
head(consol_data,5)
consol_data$precip <- vlookup(consol_data$date, vertical_data, result_column = 5,
lookup_column = 6)
head(consol_data,5)
class(consol_data)
data <- read.delim('potsdam.txt')
consol_data <- data.frame(date = as.Date(data$Date), precip = data$RSK)
head(consol_data,5)
class(consol_data)
plot(consol_data)
tibble_precip <- tibble::tibble(time = as.POSIXct(consol_data[,1]),
value = consol_data[,2]) %>%  as_tbl_time(time)
tibble_precip <- tibble::tibble(time = as.POSIXct(consol_data[,1]),
value = consol_data[,2]) %>%  as_tbl_time(time)
## for data from germany
data <- read.delim('potsdam.txt')
consol_data <- data.frame(date = as.Date(data$Date), precip = data$RSK)
head(consol_data,5)
class(consol_data)
tibble_precip <- tibble::tibble(time = as.POSIXct(consol_data[,1]),
value = consol_data[,2]) %>%  as_tbl_time(time)
month_precip <- collapse_by(tibble_precip, period = 'month')
rlang::last_error()
tibble_precip
class(consol_data$precip)
consol_data <- data.frame(date = as.Date(data$Date), precip = as.numeric(data$RSK))
## for data from germany
data <- read.delim('potsdam.txt')
consol_data <- data.frame(date = as.Date(data$Date), precip = as.numeric(data$RSK))
head(consol_data,5)
class(consol_data$precip)
tibble_precip <- tibble::tibble(time = as.POSIXct(consol_data[,1]),
value = consol_data[,2]) %>%  as_tbl_time(time)
month_precip <- collapse_by(tibble_precip, period = 'month')
station_data <- read.delim('739038.txt')
colnames(station_data) <- c('station','year','month',1:31)
head(station_data,5)
vertical_data <- gather(station_data, key = day, value = precip, 4:34)
vertical_data$date <- as.Date(paste(as.character(vertical_data$year),
as.character(vertical_data$month),
as.character(vertical_data$day),sep = '-'))
head(vertical_data,5)
consol_data <- data.frame(date = seq.Date(as.Date('1911-1-1'),as.Date('2020-12-31'),by = 'day'))
head(consol_data,5)
consol_data$precip <- vlookup(consol_data$date, vertical_data, result_column = 5,
lookup_column = 6)
head(consol_data,5)
class(consol_data)
## for data from germany
data <- read.delim('potsdam.txt')
consol_data <- data.frame(date = as.Date(data$Date), precip = as.numeric(data$RSK))
head(consol_data,5)
class(consol_data)
tibble_precip <- tibble::tibble(time = as.POSIXct(consol_data[,1]),
value = consol_data[,2]) %>%  as_tbl_time(time)
month_precip <- collapse_by(tibble_precip, period = 'month')
## for data from germany
data <- read.delim('potsdam.txt')
consol_data <- data.frame(date = as.Date(data$Date), value = as.numeric(data$RSK))
head(consol_data,5)
class(consol_data)
tibble_precip <- tibble::tibble(time = as.POSIXct(consol_data[,1]),
value = consol_data[,2]) %>%  as_tbl_time(time)
month_precip <- collapse_by(tibble_precip, period = 'month')
month_precip <- month_precip %>% group_by(time) %>%
summarise(precip = sum(.data[["value"]]))
month_precip
month_precip
tibble_precip <- tibble::tibble(time = as.POSIXct(consol_data[,1]),
value = consol_data[,2]) %>%  as_tbl_time(time)
month_precip <- collapse_by(tibble_precip, period = 'month')
month_precip
tibble_precip <- tibble::tibble(time = as.POSIXct(consol_data[,1]),
value = consol_data[,2]) %>%  as_tbl_time(time)
tibble_precip
wd <- 'C:/Users/pedro/OneDrive/@DOUTORADO/@@TU-Berlin/@Artigos/CAP 5/R'
setwd(wd)
## for data from germany
data <- read.delim('potsdam.txt')
consol_data <- data.frame(date = as.Date(data$Date), value = as.numeric(data$RSK))
head(consol_data,5)
class(consol_data)
tibble_precip <- tibble::tibble(time = as.POSIXct(consol_data[,1]),
value = consol_data[,2]) %>%  as_tbl_time(time)
month_precip <- collapse_by(tibble_precip, period = 'month')
month_precip
month_precip <- month_precip %>% group_by(time) %>%
summarise(precip = sum(.data[["value"]]))
month_precip <- collapse_by(tibble_precip, period = 'month')
collapse_by
class(consol_data$date)
consol_data <- data.frame(date = ymd(data$Date), value = as.numeric(data$RSK))
head(consol_data,5)
class(consol_data$date)
## for data from germany
data <- read.delim('potsdam.txt')
consol_data <- data.frame(date = ymd(data$Date), value = as.numeric(data$RSK))
head(consol_data,5)
class(consol_data$date)
tibble_precip <- tibble::tibble(time = as.POSIXct(consol_data[,1]),
value = consol_data[,2]) %>%  as_tbl_time(time)
month_precip <- collapse_by(tibble_precip, period = 'month')
collapse_by
data
data[,1]
## for data from germany
data <- read.delim('potsdam.txt', sep = '\t')
consol_data <- data.frame(date = ymd(data$Date), value = as.numeric(data$RSK))
head(consol_data,5)
class(consol_data$date)
tibble_precip <- tibble::tibble(time = as.POSIXct(consol_data[,1]),
value = consol_data[,2]) %>%  as_tbl_time(time)
month_precip <- collapse_by(tibble_precip, period = 'month')
## for data from germany
data <- read.delim('potsdam2.txt', sep = '\t')
consol_data <- data.frame(date = ymd(data$Date), value = as.numeric(data$RSK))
head(consol_data,5)
class(consol_data$date)
consol_data
consol_data <- data.frame(date = ymd(data$Date), value = as.numeric(data$precip))
## for data from germany
data <- read.delim('potsdam2.txt', sep = '\t')
data
consol_data <- data.frame(date = ymd(data$Date), value = as.numeric(data$precip))
data
head(data,5)
consol_data <- data.frame(date = ymd(data$date), value = as.numeric(data$precip))
head(data,5)
class(consol_data$date)
tibble_precip <- tibble::tibble(time = as.POSIXct(consol_data[,1]),
value = consol_data[,2]) %>%  as_tbl_time(time)
tibble_precip
## there are 6 monnths with NA, all in the second semester, therefore will be
## considered 0
sum(is.na(month_precip))
## there are 6 monnths with NA, all in the second semester, therefore will be
## considered 0
month_precip <- tibble_precip
sum(is.na(month_precip))
month_precip$precip[is.na(month_precip$precip)] <- 0
month_precip
month_precip
## there are 6 monnths with NA, all in the second semester, therefore will be
## considered 0
month_precip <- tibble_precip
month_precip
## there are 6 monnths with NA, all in the second semester, therefore will be
## considered 0
month_precip <- tibble_precip
sum(is.na(month_precip))
month_precip$precip[is.na(month_precip$value)] <- 0
month_precip$value[is.na(month_precip$value)] <- 0
spi.3 <- spi(month_precip$value, 3)
month_precip$spi <- spi.3$fitted
colnames(month_precip) <-  c('date','precip','spi')
head(month_precip)
## for data from germany
data <- read.delim('potsdam2.txt', sep = '\t')
consol_data <- data.frame(date = ymd(data$date), value = as.numeric(data$precip))
head(data,5)
class(consol_data$date)
tibble_precip <- tibble::tibble(time = as.POSIXct(consol_data[,1]),
value = consol_data[,2]) %>%  as_tbl_time(time)
## there are 6 monnths with NA, all in the second semester, therefore will be
## considered 0
month_precip <- tibble_precip
sum(is.na(month_precip))
month_precip$value[is.na(month_precip$value)] <- 0
spi.3 <- spi(month_precip$value, 3)
month_precip$spi <- spi.3$fitted
colnames(month_precip) <-  c('date','precip','spi')
head(month_precip)
month_precip$is.drought <- (month_precip$spi <= -1)*1
month_precip$count<- 1:nrow(month_precip)
droughts <- month_precip
droughts <- droughts %>% filter(is.drought>0)
write.table(month_precip,'data_potsdam.txt')
write.table(droughts,'data2_potsdam.txt')
write.table(month_precip,'data_potsdam.txt')
droughts
library(fdClassify)
library(fdClassify)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
pacman::p_load('ncdf4','ncdf4.helpers','PCICt','ggplot2','tidyr','dplyr','readr'
,'raster','tibbletime','lubridate','RColorBrewer','stringr','knitr'
,'tinytex','data.table','runner', 'reshape2', 'tidyquant','SPEI')
pacman::p_load('ncdf4','ncdf4.helpers','PCICt','ggplot2','tidyr','dplyr','readr'
,'raster','tibbletime','lubridate','RColorBrewer','stringr','knitr'
,'tinytex','data.table','runner', 'reshape2', 'tidyquant','SPEI')
pacman::p_load('fdClassify')
WD <- "C:/Users/pedro/OneDrive/@DOUTORADO/@@TU-Berlin/@Artigos/CAP 4/R"
setwd(WD)
de.tha <- read.csv('FLX_DE-Tha_FLUXNET2015_SUBSET_DD_1996-2014_1-4.csv')
df <- de.tha
data_et <- df[,c('TIMESTAMP','WS_F','TA_F', 'H_F_MDS', 'LE_F_MDS', 'VPD_F')]
write.csv(data_et,'de_tha_et.csv')
data_et <- na_if(data_et,-9999)
# sum(is.na(data_et$u))
colnames(data_et) <- c('time', 'wind_speed', 'temperature', 'sensible_heat', 'latent_heat', 'vapor_p_def')
head(data_et)
ggplot(data = data_et, aes(x = time))+
geom_line(col = 'brown', aes(y = sensible_heat) ,alpha = 0.5)+
geom_line(col = 'green', aes(y = latent_heat) ,alpha = 0.5)+
theme_bw() + labs(x = 'Date', y = 'Sensible and Latent heat (W/mÂ²)')
sum(is.na(data_et))
pacman::p_load('ncdf4','ncdf4.helpers','PCICt','ggplot2','tidyr','dplyr','readr'
,'raster','tibbletime','lubridate','RColorBrewer','stringr','knitr'
,'tinytex','data.table','runner', 'reshape2', 'tidyquant','SPEI')
pacman::p_load('fdClassify')
WD <- "C:/Users/pedro/OneDrive/@DOUTORADO/@@TU-Berlin/@Artigos/CAP 4/R"
setwd(WD)
df <- de.tha
data_et <- df[,c('TIMESTAMP','WS_F','TA_F', 'H_F_MDS', 'LE_F_MDS', 'VPD_F')]
write.csv(data_et,'de_tha_et.csv')
# data_et <- read.csv('de_tha_et.csv')
data_et$TIMESTAMP <- ymd(data_et$TIMESTAMP)
data_et <- na_if(data_et,-9999)
# sum(is.na(data_et$u))
colnames(data_et) <- c('time', 'wind_speed', 'temperature', 'sensible_heat', 'latent_heat', 'vapor_p_def')
head(data_et)
ggplot(data = data_et, aes(x = time))+
geom_line(col = 'brown', aes(y = sensible_heat) ,alpha = 0.5)+
geom_line(col = 'green', aes(y = latent_heat) ,alpha = 0.5)+
theme_bw() + labs(x = 'Date', y = 'Sensible and Latent heat (W/mÂ²)')
sum(is.na(data_et))
psychometric_c <- 0.0674
data_et$vapor_p_sat <- 0.661*exp(17.27*data_et$temperature / (237.3 + data_et$temperature))
data_et$slope_vapor_p <- 4098*data_et$vapor_p_sat/(237.3 + data_et$temperature)^2
data_et$vapor_p_def <- 0.1*data_et$vapor_p_def #from hPa to kPa
data_et$heat_flux <- (data_et$sensible_heat +
data_et$latent_heat)*86400/10^6 #from W m-2 to M m-2 day-2
# calculate ET0 by Penman-Monteith equation
data_et$et0 <- (0.408*data_et$slope_vapor_p*data_et$heat_flux +
psychometric_c*(900/(data_et$temperature + 273))*data_et$wind_speed*data_et$vapor_p_def)
data_et$et0 <- data_et$et0/(data_et$slope_vapor_p + psychometric_c*(1 + 0.34*data_et$wind_speed))
et0 <- data.frame(time = data_et$time, et0 = data_et$et0)
et0$et0[et0$et0 < 0] <- 0
write.table(data_et,'et0_data.txt')
write.table(data_et,'et0_data.txt')
ggplot(data = et0, aes(x = time, y = et0))+
geom_line()
# Function to arrange data in list of years
f.year <- function(i,year.var,day.var){
year.var$i <- filter(day.var, day.var$year == i)
}
#define a column of years and reload start and end of series
et0$year <- year(et0$time)
beg <- min(et0$year) #year of the series beginning
end <- max(et0$year)
year.et0 <- NULL
#organize years in separated lists
year.et0 <- lapply(beg:end,f.year, year.et0, et0)
#Collapse data on each year (element of the list) into pentads
pentad.et0 <- NULL
for (i in 1:n.years){
year.var <- year.et0[[i]][1:2]
year.var <- tibble::tibble(time = as.POSIXct(year.var[,1]),
value = year.var[,2]) %>% as_tbl_time(time)
pentad.var <- collapse_by(year.var, period = '5 days')
pentad.var <- pentad.var %>% group_by(time) %>%
summarise(et0 = mean(.data[["value"]]))
#in leap years, the last pentad has 6 days
if (nrow(pentad.var) == 74){
pentad.var$et0[73] <- (pentad.var$et0[73]*5 + pentad.var$et0[74])/6
}
pentad.et0 <- cbind(pentad.et0,pentad.var$et0)
}
ts.et0 <- ts(c(pentad.et0), frequency = 73, start = beg)
#Collapse data on each year (element of the list) into pentads
pentad.et0 <- NULL
for (i in 1:n.years){
year.var <- year.et0[[i]][1:2]
year.var <- tibble::tibble(time = as.POSIXct(year.var[,1]),
value = year.var[,2]) %>% as_tbl_time(time)
pentad.var <- collapse_by(year.var, period = '5 days')
pentad.var <- pentad.var %>% group_by(time) %>%
summarise(et0 = mean(.data[["value"]]))
#in leap years, the last pentad has 6 days
if (nrow(pentad.var) == 74){
pentad.var$et0[73] <- (pentad.var$et0[73]*5 + pentad.var$et0[74])/6
}
pentad.et0 <- cbind(pentad.et0,pentad.var$et0)
}
n.years <- length(year.et0)
#Collapse data on each year (element of the list) into pentads
pentad.et0 <- NULL
for (i in 1:n.years){
year.var <- year.et0[[i]][1:2]
year.var <- tibble::tibble(time = as.POSIXct(year.var[,1]),
value = year.var[,2]) %>% as_tbl_time(time)
pentad.var <- collapse_by(year.var, period = '5 days')
pentad.var <- pentad.var %>% group_by(time) %>%
summarise(et0 = mean(.data[["value"]]))
#in leap years, the last pentad has 6 days
if (nrow(pentad.var) == 74){
pentad.var$et0[73] <- (pentad.var$et0[73]*5 + pentad.var$et0[74])/6
}
pentad.et0 <- cbind(pentad.et0,pentad.var$et0)
}
pentad.et0 <- pentad.et0[1:73,] # non-desireble 74-th removed.
ts.et0 <- ts(c(pentad.et0), frequency = 73, start = beg)
plot(ts.et0, ylab = 'ET_0 (mm.day^-1)', main = 'Potential Evapotranspiration')
### Function to obtain percentiles from pentad-SWC dataframe
f.percentile <- function(vector){
v.percentile <- NULL
a1 <- quantile(vector,prob = seq(0,1,0.01), na.rm = T) #101 elements
a2 <- unique(as.data.frame(a1), fromLast = TRUE)
a3 <- rownames(a2)
a4 <- as.integer(strsplit(a3, "%")) #from 0 to 100
v.percentile <- sapply(1:length(vector),FUN = function(i)
v.percentile[i] = a4[which.min(abs(a2$a1 - vector[i]))])
idx <- !(sapply(v.percentile, length)) ##Identify positions with no length (Integer 0) -- previous NA values
v.percentile[idx] <- NA ## replaces integer(0) for NA
v.percentile <- unlist(v.percentile)
}
# get percentiles
percentile.et0 <- t(apply(pentad.et0,1, f.percentile))
ts.percentile.et0 <- ts(c(percentile.et0), frequency = 73, start = beg)
#backup of processing
write.csv(percentile.et0, 'perc_et0.csv')
write.csv(pentad.et0, 'pent_et0.csv')
plot.ts(ts.percentile.et0, ylab = 'Percentile - ET_0 (%)', main = 'Percentiles of Potential Evapotranspiration')
##remove NA
data.table <- data.frame(time = time(ts.percentile.et0),
index = 1:length(percentile.et0),
percentile = c(percentile.et0),
et0 = c(pentad.et0))
#Remove eventual NA in the beginning of the series
firstNonNA <- min(which(!is.na(data.table$percentile)))
data.table <- data.table[firstNonNA:nrow(data.table),]
data.table$delta <- NA
auxiliar1 <- unlist(lapply(4:nrow(data.table),
function(i) data.table$percentile[i] -
data.table$percentile[i-3])) %>%
c(rep(NA,3),.)
data.table$delta <- auxiliar1
#Classification
data.table$fd <- 0
limit.upwards <- 5 #max recuperation over sustain period
for (i in 4:(nrow(data.table)-3)){
data.table$fd[i] <- (data.table$delta[i] <= -50) *
(data.table$percentile[i+1] - data.table$percentile[i] <= limit.upwards) *
(data.table$percentile[i+2] - data.table$percentile[i] <= limit.upwards) *
(data.table$percentile[i+3] - data.table$percentile[i] <= limit.upwards)
}
info.fd <- data.table[data.table$fd == 1,]
plot(data.table$time, data.table$et0, type = 'l', col = 'orange')+
lines(data.table$time, data.table$fd*20) #+
info.fd
rm(list = ls()) #clean environment
# Function to arrange data in list of years
f.year <- function(i,day.var,year.var=NULL){
year.var$i <- filter(day.var, day.var$year == i)
return(year.var$i)
}
# Function to organize data into pentads
f.pentad <- function(data.var){
#define a column of years and reload start and end of series
data.var$year <- year(data.var[,1])
beg <- min(data.var$year) #year of the series beginning
end <- max(data.var$year)
year.var.list <- lapply(beg:end,f.year, data.var)
n.years <- length(year.var.list)
pentad.matrix<- NULL
pentad.series <- NULL
for (i in 1:n.years){
year.var <- year.var.list[[i]][1:2]
year.var <- tibble::tibble(time = as.POSIXct(year.var[,1]),
value = year.var[,2]) %>% as_tbl_time(time)
pentad.var <- collapse_by(year.var, period = '5 days')
pentad.var <- pentad.var %>% group_by(time) %>%
summarise(var = mean(.data[["value"]]))
#in leap years, the last pentad has 6 days
if (nrow(pentad.var) == 74){
pentad.var$var[73] <- (pentad.var$var[73]*5 + pentad.var$var[74])/6
}
pentad.matrix <- cbind(pentad.matrix,pentad.var$var)
#set dataframe with all years removing undesireble 74th pentad
pentad.series <- rbind(pentad.series, pentad.var[1:73,])
}
# by coercion a 74th pentad is added in all years. Its value is equal to the
# first pentad. For the leap years the 73th pentad already contains the last
# day (see comments above). Here we remove the non-desirable 74-th pentad
pentad.matrix <- pentad.matrix[1:73,]
output<- list('pentad_timestamp' = pentad.series, 'pentad_matrix' = pentad.matrix)
return(output)
}
# Function to get percentiles
f.percentile <- function(vector){
v.percentile <- NULL
a1 <- quantile(vector,prob = seq(0,1,0.01), na.rm = T) #101 elements
a2 <- unique(as.data.frame(a1), fromLast = TRUE)
a3 <- rownames(a2)
a4 <- as.integer(strsplit(a3, "%")) #from 0 to 100
v.percentile <- sapply(1:length(vector),FUN = function(i)
v.percentile[i] = a4[which.min(abs(a2$a1 - vector[i]))])
idx <- !(sapply(v.percentile, length))
v.percentile[idx] <- NA
v.percentile <- unlist(v.percentile)
}
# Function to calculate ET0 from Penman-Monteith
penman_day <- function(v.time, v.wind, v.temp, v.vpd, v.heatflux, altitude = 0){
#calculate the local pressure based on the altitude. If none is provided sea level is used.
# altitude = 0
Patm <- 101.3*(1 - 2.22*altitude/100000)^5.26
psychometric_c <- 0.000665*Patm
v.time <- ymd(v.time)
vapor_p_sat <- 0.661*exp(17.27*v.temp / (237.3 + v.temp))
slope_vapor_p <- 4098*vapor_p_sat/(237.3 + v.temp)^2
#from W m-2 to M m-2 day-2
v.et0 <- 0.408*slope_vapor_p*v.heatflux +
psychometric_c*(900/(v.temp + 273))*v.wind*v.vpd
v.et0 <- v.et0/(slope_vapor_p + psychometric_c*(1 + 0.34*v.wind))
et0 <- data.frame(time = v.time, et0 = v.et0)
et0$et0[et0$et0 < 0] <- 0
return(et0)
}
#Classification function
Pendergrass2020 <- function(data.et0, limit.up = 10){
#get pentads
et0 <- as.data.frame(data.et0)
et0$time <- as.Date(et0$time)
pentad.et0.list <- f.pentad(et0)
series.et0 <- pentad.et0.list$pentad_timestamp
pentad.et0 <- pentad.et0.list$pentad_matrix
# get percentiles
percentile.et0 <- t(apply(pentad.et0,1, f.percentile))
ts.percentile.et0 <- ts(c(percentile.et0), frequency = 73, start = min(year(series.et0$time)))
data.table <- data.frame(time = time(ts.percentile.et0),
index = 1:length(percentile.et0),
percentile = c(percentile.et0),
et0 = c(pentad.et0))
#Remove eventual NA in the beginning of the series
firstNonNA <- min(which(!is.na(data.table$percentile)))
data.table <- data.table[firstNonNA:nrow(data.table),]
data.table$delta <- NA
auxiliar1 <- unlist(lapply(4:nrow(data.table),
function(i) data.table$percentile[i] -
data.table$percentile[i-3])) %>%
c(rep(NA,3),.)
data.table$delta <- auxiliar1
#Classification
data.table$fd <- 0
limit.upwards <- limit.up #max recuperation over sustain period
for (i in 4:(nrow(data.table)-3)){
data.table$fd[i] <- (data.table$delta[i] <= -50) *
(data.table$percentile[i+1] - data.table$percentile[i] <= limit.upwards) *
(data.table$percentile[i+2] - data.table$percentile[i] <= limit.upwards) *
(data.table$percentile[i+3] - data.table$percentile[i] <= limit.upwards)
}
fd.info <- data.table[data.table$fd == 1,]
output <- list('ET0_timeseries' = data.table, 'FD_info' = fd.info)
return(output)
}
####################### test #################################
de.tha <- read.csv('FLX_DE-Tha_FLUXNET2015_SUBSET_DD_1996-2014_1-4.csv')
####################### test #################################
de.tha <- read.csv('FLX_DE-Tha_FLUXNET2015_SUBSET_DD_1996-2014_1-4.csv')
df <- de.tha
df <- de.tha
data_et <- df[,c('TIMESTAMP','WS_F','TA_F', 'H_F_MDS', 'LE_F_MDS', 'VPD_F')]
data_et$TIMESTAMP <- ymd(data_et$TIMESTAMP)
data_et <- na_if(data_et,-9999)
colnames(data_et) <- c('time', 'wind_speed', 'temperature', 'sensible_heat', 'latent_heat', 'vapor_p_def')
## N3cessary conversions
data_et$vapor_p_def <- 0.1*data_et$vapor_p_def
data_et$heat_flux <- (data_et$sensible_heat +
data_et$latent_heat)*86400/10^6
et0 <- penman_day(v.time = data_et$time, v.wind = data_et$wind_speed, v.temp = data_et$temperature, v.vpd =data_et$vapor_p_def,v.heatflux = data_et$heat_flux)
fd.tha <- Pendergrass2020(et0, limit.up = 5)
head(fd.tha[[1]])
fd.tha[[2]]
library(fdClassify)
actual_evap_day <- function(v.time, v.latent_heat, v.temperature = 20){
latent_d <- (2500.96 - 2.37*v.temperature)*0.001
density_w <- 999.84 - 0.005*v.temperature^2
#get actual evapotranspiration
v.evap <- 89.4*v.latent_heat*(latent_d*density_w)^-1
#check if there are ETa lower then zero and set those values to zero (eliminate
# condensation)
v.evap[v.evap < 0] <- 0
eta <- data.frame(time = v.time, eta = v.evap)
return(eta)
}
library(fdClassify)
library(fdClassify)
library(fdClassify)
library(fdClassify)
library(fdClassify)
